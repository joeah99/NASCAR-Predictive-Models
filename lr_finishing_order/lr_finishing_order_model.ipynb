{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06236c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# make parent folder importable\n",
    "parent_folder = Path.cwd().parent\n",
    "sys.path.append(str(parent_folder))\n",
    "\n",
    "# import config\n",
    "from config import DATA_DIR\n",
    "\n",
    "results_file = DATA_DIR / \"10-20-results.csv\"\n",
    "misc_file = DATA_DIR / \"10-20-misc.csv\"\n",
    "stages_file = DATA_DIR / \"10-20-stages.csv\"\n",
    "practice_file = DATA_DIR / \"10-20-practice.csv\"\n",
    "\n",
    "results = pd.read_csv(results_file)\n",
    "misc = pd.read_csv(misc_file)\n",
    "stages = pd.read_csv(stages_file)\n",
    "practice = pd.read_csv(practice_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7c7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation of practice data to eliminate 'duplicate' observations \n",
    "# the only race consistently having multiple practices is the Daytona500, but I think this is best practice for now\n",
    "practice_agg = (\n",
    "    practice.groupby([\"race_id\", \"driver_id\"])\n",
    "    .agg({\n",
    "        \"BestLapRank\" : \"mean\",\n",
    "        \"OverAllAvgRank\" : \"mean\",\n",
    "        \"Con5LapRank\" : \"mean\",\n",
    "        \"Con10LapRank\" : \"mean\",\n",
    "        \"Con15LapRank\" : \"mean\",\n",
    "        \"Con20LapRank\" : \"mean\",\n",
    "        \"Con25LapRank\" : \"mean\",\n",
    "        \"Con30LapRank\" : \"mean\"\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1500bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting the stage dataset to eliminate 'duplicate' observations\n",
    "# doing this rather than aggregation since I want to preserve stage 1 and stage 2 as seperate parts of the race (not averaged together)\n",
    "stages_wide = stages.pivot_table(\n",
    "    index=[\"race_id\", \"driver_id\"],\n",
    "    columns=\"stage_number\",\n",
    "    values=[\"position\", \"stage_points\"]\n",
    ")\n",
    "\n",
    "stages_wide.columns = [\n",
    "    f\"stage_{col[1]}_{col[0]}\" for col in stages_wide.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "stages_wide = stages_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8a0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data merging\n",
    "df = results.copy()\n",
    "df = pd.merge(df, misc, on=[\"race_id\", \"driver_id\"], how=\"outer\", suffixes=(\"\", \"_misc\"))\n",
    "df = pd.merge(df, stages_wide, on=[\"race_id\", \"driver_id\"], how=\"outer\")\n",
    "df = pd.merge(df, practice_agg, on=[\"race_id\", \"driver_id\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ae0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows duplicates (same driver_id AND race_id in multiple rows)\n",
    "# dupes = df[df.duplicated(subset=[\"race_id\", \"driver_id\"], keep=False)]\n",
    "# print(dupes.sort_values([\"race_id\", \"driver_id\"]))\n",
    "# ensure no duplicates\n",
    "assert df.duplicated(subset=[\"race_id\", \"driver_id\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cc3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, rolling_lagging as rolling_lagging\n",
    "importlib.reload(rolling_lagging)\n",
    "from rolling_lagging import lagging_rolling_generator, reconcile_driver_carteams\n",
    "\n",
    "lagroll_features = [\n",
    "    \"finishing_position\", \n",
    "    \"starting_position\",\n",
    "    \"points_position\", \n",
    "    \"stage_1_position\", \n",
    "    \"stage_2_position\", \n",
    "    \"mid_ps\", \n",
    "    \"closing_ps\", \n",
    "    \"avg_ps\", \n",
    "    \"BestLapRank\", \n",
    "    \"OverAllAvgRank\",\n",
    "    \"laps_completed\", \n",
    "    \"laps_led\", \n",
    "    \"points_earned\", \n",
    "    \"fast_laps\", \n",
    "    \"top15_laps\", \n",
    "    \"rating\"\n",
    "]\n",
    "\n",
    "# feature engineering, lagging & rolling averages\n",
    "# df, features, sort_list, filter_list, windows_list, suffix, min_periods = 1\n",
    "\n",
    "# directly recent races (momentum):\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\"], [3, 5, 10], \"general\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\"], [3, 5, 10], \"general_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\"], [3, 5, 10], \"general_carteam\", 1)\n",
    "\n",
    "# most recent at track type:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_type\"], [3, 5, 10], \"tracktype\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_type\"], [3, 5, 10], \"tracktype_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_type\"], [3, 5, 10], \"tracktype_carteam\", 1)\n",
    "\n",
    "# most recent at specific track:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_name\"], [3, 5], \"track\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_name\"], [3, 5], \"track_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_name\"], [3, 5], \"track_carteam\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c355e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs in lagroll features with carteam or team averages\n",
    "# df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"tracktype\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5], \"track\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c354192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['starting_position', 'BestLapRank', 'OverAllAvgRank', 'finishing_position_lag1_general', 'finishing_position_roll3_general', 'finishing_position_roll5_general', 'finishing_position_roll10_general', 'starting_position_lag1_general', 'starting_position_roll3_general', 'starting_position_roll5_general', 'starting_position_roll10_general', 'points_position_lag1_general', 'points_position_roll3_general', 'points_position_roll5_general', 'points_position_roll10_general', 'stage_1_position_lag1_general', 'stage_1_position_roll3_general', 'stage_1_position_roll5_general', 'stage_1_position_roll10_general', 'stage_2_position_lag1_general', 'stage_2_position_roll3_general', 'stage_2_position_roll5_general', 'stage_2_position_roll10_general', 'mid_ps_lag1_general', 'mid_ps_roll3_general', 'mid_ps_roll5_general', 'mid_ps_roll10_general', 'closing_ps_lag1_general', 'closing_ps_roll3_general', 'closing_ps_roll5_general', 'closing_ps_roll10_general', 'avg_ps_lag1_general', 'avg_ps_roll3_general', 'avg_ps_roll5_general', 'avg_ps_roll10_general', 'BestLapRank_lag1_general', 'BestLapRank_roll3_general', 'BestLapRank_roll5_general', 'BestLapRank_roll10_general', 'OverAllAvgRank_lag1_general', 'OverAllAvgRank_roll3_general', 'OverAllAvgRank_roll5_general', 'OverAllAvgRank_roll10_general', 'laps_completed_lag1_general', 'laps_completed_roll3_general', 'laps_completed_roll5_general', 'laps_completed_roll10_general', 'laps_led_lag1_general', 'laps_led_roll3_general', 'laps_led_roll5_general', 'laps_led_roll10_general', 'points_earned_lag1_general', 'points_earned_roll3_general', 'points_earned_roll5_general', 'points_earned_roll10_general', 'fast_laps_lag1_general', 'fast_laps_roll3_general', 'fast_laps_roll5_general', 'fast_laps_roll10_general', 'top15_laps_lag1_general', 'top15_laps_roll3_general', 'top15_laps_roll5_general', 'top15_laps_roll10_general', 'rating_lag1_general', 'rating_roll3_general', 'rating_roll5_general', 'rating_roll10_general', 'finishing_position_lag1_tracktype', 'finishing_position_roll3_tracktype', 'finishing_position_roll5_tracktype', 'finishing_position_roll10_tracktype', 'starting_position_lag1_tracktype', 'starting_position_roll3_tracktype', 'starting_position_roll5_tracktype', 'starting_position_roll10_tracktype', 'points_position_lag1_tracktype', 'points_position_roll3_tracktype', 'points_position_roll5_tracktype', 'points_position_roll10_tracktype', 'stage_1_position_lag1_tracktype', 'stage_1_position_roll3_tracktype', 'stage_1_position_roll5_tracktype', 'stage_1_position_roll10_tracktype', 'stage_2_position_lag1_tracktype', 'stage_2_position_roll3_tracktype', 'stage_2_position_roll5_tracktype', 'stage_2_position_roll10_tracktype', 'mid_ps_lag1_tracktype', 'mid_ps_roll3_tracktype', 'mid_ps_roll5_tracktype', 'mid_ps_roll10_tracktype', 'closing_ps_lag1_tracktype', 'closing_ps_roll3_tracktype', 'closing_ps_roll5_tracktype', 'closing_ps_roll10_tracktype', 'avg_ps_lag1_tracktype', 'avg_ps_roll3_tracktype', 'avg_ps_roll5_tracktype', 'avg_ps_roll10_tracktype', 'BestLapRank_lag1_tracktype', 'BestLapRank_roll3_tracktype', 'BestLapRank_roll5_tracktype', 'BestLapRank_roll10_tracktype', 'OverAllAvgRank_lag1_tracktype', 'OverAllAvgRank_roll3_tracktype', 'OverAllAvgRank_roll5_tracktype', 'OverAllAvgRank_roll10_tracktype', 'laps_completed_lag1_tracktype', 'laps_completed_roll3_tracktype', 'laps_completed_roll5_tracktype', 'laps_completed_roll10_tracktype', 'laps_led_lag1_tracktype', 'laps_led_roll3_tracktype', 'laps_led_roll5_tracktype', 'laps_led_roll10_tracktype', 'points_earned_lag1_tracktype', 'points_earned_roll3_tracktype', 'points_earned_roll5_tracktype', 'points_earned_roll10_tracktype', 'fast_laps_lag1_tracktype', 'fast_laps_roll3_tracktype', 'fast_laps_roll5_tracktype', 'fast_laps_roll10_tracktype', 'top15_laps_lag1_tracktype', 'top15_laps_roll3_tracktype', 'top15_laps_roll5_tracktype', 'top15_laps_roll10_tracktype', 'rating_lag1_tracktype', 'rating_roll3_tracktype', 'rating_roll5_tracktype', 'rating_roll10_tracktype', 'finishing_position_lag1_track', 'finishing_position_roll3_track', 'finishing_position_roll5_track', 'starting_position_lag1_track', 'starting_position_roll3_track', 'starting_position_roll5_track', 'points_position_lag1_track', 'points_position_roll3_track', 'points_position_roll5_track', 'stage_1_position_lag1_track', 'stage_1_position_roll3_track', 'stage_1_position_roll5_track', 'stage_2_position_lag1_track', 'stage_2_position_roll3_track', 'stage_2_position_roll5_track', 'mid_ps_lag1_track', 'mid_ps_roll3_track', 'mid_ps_roll5_track', 'closing_ps_lag1_track', 'closing_ps_roll3_track', 'closing_ps_roll5_track', 'avg_ps_lag1_track', 'avg_ps_roll3_track', 'avg_ps_roll5_track', 'BestLapRank_lag1_track', 'BestLapRank_roll3_track', 'BestLapRank_roll5_track', 'OverAllAvgRank_lag1_track', 'OverAllAvgRank_roll3_track', 'OverAllAvgRank_roll5_track', 'laps_completed_lag1_track', 'laps_completed_roll3_track', 'laps_completed_roll5_track', 'laps_led_lag1_track', 'laps_led_roll3_track', 'laps_led_roll5_track', 'points_earned_lag1_track', 'points_earned_roll3_track', 'points_earned_roll5_track', 'fast_laps_lag1_track', 'fast_laps_roll3_track', 'fast_laps_roll5_track', 'top15_laps_lag1_track', 'top15_laps_roll3_track', 'top15_laps_roll5_track', 'rating_lag1_track', 'rating_roll3_track', 'rating_roll5_track']\n"
     ]
    }
   ],
   "source": [
    "# dropping features irrelevant to benchmark model\n",
    "\n",
    "# keeping for visibility when reviewing df as csv\n",
    "keep_cols = [\n",
    "    \"finishing_position\", \"race_id\", \"race_season\", \"race_name\", \"track_name\", \"race_date\",\n",
    "    \"driver_fullname\", \"driver_id\", \"car_number\", \"team_name\", \"car_make\",\n",
    "    \"crew_chief_fullname\", \"finishing_status\"\n",
    "]\n",
    "\n",
    "# remove the actual in-race data per observation but keep P&Q\n",
    "in_race_leakage = [\n",
    "    'finishing_position', 'laps_completed', 'laps_led', 'points_earned', 'playoff_points_earned', \n",
    "    'points_position', 'mid_ps', 'closing_ps', 'avg_ps', 'fast_laps', 'top15_laps', 'rating', \n",
    "    'stage_1_position', 'stage_2_position'\n",
    "]\n",
    "\n",
    "# keep engineered driver features for model, but not team / carteam features (those were only used to fill missing driver stats)\n",
    "lagroll_cols = [\n",
    "    col for col in df.columns\n",
    "    if any(feat in col for feat in lagroll_features)\n",
    "    and \"_team\" not in col\n",
    "    and \"_carteam\" not in col\n",
    "    and col not in in_race_leakage\n",
    "]\n",
    "print(lagroll_cols)\n",
    "\n",
    "final_cols = keep_cols + lagroll_cols\n",
    "df = df[final_cols]\n",
    "# df.to_csv(\"training_ready_bench.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb9ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'ridge__alpha': 1600}\n",
      "starting_position                  1.093034\n",
      "OverAllAvgRank                     0.473072\n",
      "BestLapRank                        0.413505\n",
      "mid_ps_roll10_general              0.348017\n",
      "OverAllAvgRank_roll5_general       0.329482\n",
      "laps_led_roll5_tracktype           0.263406\n",
      "points_position_lag1_general       0.238216\n",
      "mid_ps_lag1_general                0.212826\n",
      "BestLapRank_roll5_track            0.208415\n",
      "points_earned_roll3_general        0.196703\n",
      "OverAllAvgRank_roll3_tracktype     0.195675\n",
      "stage_1_position_roll10_general    0.192749\n",
      "stage_1_position_lag1_tracktype    0.191542\n",
      "points_position_roll10_general     0.190011\n",
      "points_position_roll5_general      0.185861\n",
      "avg_ps_roll5_track                 0.181618\n",
      "OverAllAvgRank_roll5_track         0.178165\n",
      "points_position_roll3_general      0.171581\n",
      "laps_led_roll10_tracktype          0.171491\n",
      "mid_ps_roll5_tracktype             0.164186\n",
      "dtype: float64\n",
      "\n",
      "Spearman mean: 0.437\n",
      "Spearman median: 0.457\n",
      "Number of races evaluated: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_12376\\2743412880.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"weighted_score_lr\"] = best_model.predict(df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_12376\\2743412880.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"pred_rank_lr\"] = df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_12376\\2743412880.py:53: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(race_spearman)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "df_train = df.dropna(subset=[\"finishing_position\"]).copy()\n",
    "X = df_train[lagroll_cols]\n",
    "y = df_train[\"finishing_position\"]\n",
    "groups = df_train[\"race_id\"]\n",
    "\n",
    "# Define pipeline: impute -> scale -> model\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge())\n",
    "])\n",
    "\n",
    "# Parameter grid for alpha\n",
    "param_grid = {\"ridge__alpha\": [1000, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "# Grouped CV\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "grid.fit(X, y, groups=groups)\n",
    "\n",
    "print(\"Best alpha:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Get coefficients\n",
    "ridge_model = best_model.named_steps[\"ridge\"]\n",
    "coef = pd.Series(ridge_model.coef_, index=lagroll_cols)\n",
    "print(coef.sort_values(ascending=False).head(20))\n",
    "\n",
    "# Apply to full df\n",
    "df[\"weighted_score_lr\"] = best_model.predict(df[lagroll_cols])\n",
    "df[\"pred_rank_lr\"] = df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)  \n",
    "# ascending=True because lower predicted finish = better (P1)\n",
    "\n",
    "def race_spearman(g):\n",
    "    if g[\"weighted_score_lr\"].nunique() < 2:\n",
    "        return np.nan\n",
    "    return spearmanr(g[\"weighted_score_lr\"], g[\"finishing_position\"]).correlation\n",
    "\n",
    "race_corrs = (\n",
    "    df.dropna(subset=[\"finishing_position\"])\n",
    "      .groupby(\"race_id\")\n",
    "      .apply(race_spearman)\n",
    ")\n",
    "\n",
    "print(\"\\nSpearman mean:\", race_corrs.mean().round(3))\n",
    "print(\"Spearman median:\", race_corrs.median().round(3))\n",
    "print(\"Number of races evaluated:\", race_corrs.notna().sum())\n",
    "\n",
    "df.to_csv(\"analysis_ready_bench.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
