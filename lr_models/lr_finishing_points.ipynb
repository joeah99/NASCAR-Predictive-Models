{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d81fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68061dc8b0d476998e5ee4b7d0c8886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Series: ', options=('Cup', 'Xfinity', 'Trucks'), value='Cup')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# make parent folder importable\n",
    "parent_folder = Path.cwd().parent\n",
    "sys.path.append(str(parent_folder))\n",
    "\n",
    "# import config\n",
    "from config import DATA_DIR\n",
    "\n",
    "series_dropdown = widgets.Dropdown(\n",
    "    options=[\"Cup\", \"Xfinity\", \"Trucks\"],\n",
    "    description=\"Series: \"\n",
    ")\n",
    "display(series_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06236c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if series_dropdown.value == \"Cup\":\n",
    "    results_file = DATA_DIR / \"10-20-results.csv\"\n",
    "    misc_file = DATA_DIR / \"10-20-misc.csv\"\n",
    "    stages_file = DATA_DIR / \"10-20-stages.csv\"\n",
    "    practice_file = DATA_DIR / \"10-20-practice.csv\"\n",
    "\n",
    "elif series_dropdown.value == \"Xfinity\":\n",
    "    # print(\"No Xfinity data files available yet.\")\n",
    "    results_file = DATA_DIR / \"10-20-xfinity-results.csv\"\n",
    "    misc_file = DATA_DIR / \"10-20-xfinity-misc.csv\"\n",
    "    stages_file = DATA_DIR / \"10-20-xfinity-stages.csv\"\n",
    "    practice_file = DATA_DIR / \"10-20-xfinity-practice.csv\"\n",
    "\n",
    "elif series_dropdown.value == \"Trucks\":\n",
    "    # print(\"No Truck data files available yet.\")\n",
    "    results_file = DATA_DIR / \"10-20-trucks-results.csv\"\n",
    "    misc_file = DATA_DIR / \"10-20-trucks-misc.csv\"\n",
    "    stages_file = DATA_DIR / \"10-20-trucks-stages.csv\"\n",
    "    practice_file = DATA_DIR / \"10-20-trucks-practice.csv\"\n",
    "\n",
    "else: \n",
    "    print(\"An error selecting series occurred.\")\n",
    "\n",
    "results = pd.read_csv(results_file)\n",
    "misc = pd.read_csv(misc_file)\n",
    "stages = pd.read_csv(stages_file)\n",
    "practice = pd.read_csv(practice_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7c7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation of practice data to eliminate 'duplicate' observations \n",
    "# the only race consistently having multiple practices is the Daytona500, but I think this is best practice for now\n",
    "practice_agg = (\n",
    "    practice.groupby([\"race_id\", \"driver_id\"])\n",
    "    .agg({\n",
    "        \"BestLapRank\" : \"mean\",\n",
    "        \"OverAllAvgRank\" : \"mean\",\n",
    "        \"Con5LapRank\" : \"mean\",\n",
    "        \"Con10LapRank\" : \"mean\",\n",
    "        \"Con15LapRank\" : \"mean\",\n",
    "        \"Con20LapRank\" : \"mean\",\n",
    "        \"Con25LapRank\" : \"mean\",\n",
    "        \"Con30LapRank\" : \"mean\"\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1500bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting the stage dataset to eliminate 'duplicate' observations\n",
    "# doing this rather than aggregation since I want to preserve stage 1 and stage 2 as seperate parts of the race (not averaged together)\n",
    "stages_wide = stages.pivot_table(\n",
    "    index=[\"race_id\", \"driver_id\"],\n",
    "    columns=\"stage_number\",\n",
    "    values=[\"position\", \"stage_points\"]\n",
    ")\n",
    "\n",
    "stages_wide.columns = [\n",
    "    f\"stage_{col[1]}_{col[0]}\" for col in stages_wide.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "stages_wide = stages_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8a0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data merging\n",
    "df = results.copy()\n",
    "df = pd.merge(df, misc, on=[\"race_id\", \"driver_id\"], how=\"outer\", suffixes=(\"\", \"_misc\"))\n",
    "df = pd.merge(df, stages_wide, on=[\"race_id\", \"driver_id\"], how=\"outer\")\n",
    "df = pd.merge(df, practice_agg, on=[\"race_id\", \"driver_id\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ae0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [race_id, race_season, race_name, track_name, race_date, finishing_position, starting_position, car_number, driver_fullname, driver_id, team_name, car_make, sponsor, crew_chief_fullname, laps_completed, finishing_status, laps_led, times_led, points_earned, diff_laps, diff_time, playoff_points_earned, points_position, points_delta, disqualified, qualifying_order, qualifying_position, qualifying_speed, track_type, track_length, race_name_misc, sch_laps, act_laps, start_ps, mid_ps, ps, closing_ps, closing_laps_diff, best_ps, worst_ps, avg_ps, passes_gf, passing_diff, passed_gf, quality_passes, fast_laps, top15_laps, lead_laps, laps, rating, stage_1_position, stage_2_position, stage_3_position, stage_1_stage_points, stage_2_stage_points, stage_3_stage_points, BestLapRank, OverAllAvgRank, Con5LapRank, Con10LapRank, Con15LapRank, Con20LapRank, Con25LapRank, Con30LapRank]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# shows duplicates (same driver_id AND race_id in multiple rows)\n",
    "dupes = df[df.duplicated(subset=[\"race_id\", \"driver_id\"], keep=False)]\n",
    "print(dupes.sort_values([\"race_id\", \"driver_id\"]))\n",
    "# ensure no duplicates\n",
    "assert df.duplicated(subset=[\"race_id\", \"driver_id\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cc3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, rolling_lagging as rolling_lagging\n",
    "importlib.reload(rolling_lagging)\n",
    "from rolling_lagging import lagging_rolling_generator, reconcile_driver_carteams\n",
    "\n",
    "lagroll_features = [\n",
    "    \"finishing_position\", \n",
    "    \"starting_position\",\n",
    "    \"points_position\", \n",
    "    \"stage_1_position\", \n",
    "    \"stage_2_position\", \n",
    "    \"mid_ps\", \n",
    "    \"closing_ps\", \n",
    "    \"avg_ps\", \n",
    "    \"BestLapRank\", \n",
    "    \"OverAllAvgRank\",\n",
    "    \"laps_completed\", \n",
    "    \"laps_led\", \n",
    "    \"points_earned\", \n",
    "    \"fast_laps\", \n",
    "    \"top15_laps\", \n",
    "    \"rating\"\n",
    "]\n",
    "\n",
    "# feature engineering, lagging & rolling averages\n",
    "# df, features, sort_list, filter_list, windows_list, suffix, min_periods = 1\n",
    "\n",
    "# directly recent races (momentum):\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\"], [3, 5, 10], \"general\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\"], [3, 5, 10], \"general_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\"], [3, 5, 10], \"general_carteam\", 1)\n",
    "\n",
    "# most recent at track type:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_type\"], [3, 5, 10], \"tracktype\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_type\"], [3, 5, 10], \"tracktype_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_type\"], [3, 5, 10], \"tracktype_carteam\", 1)\n",
    "\n",
    "# most recent at specific track:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_name\"], [3, 5], \"track\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_name\"], [3, 5], \"track_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_name\"], [3, 5], \"track_carteam\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c355e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs in lagroll features with carteam or team averages\n",
    "# df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"tracktype\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5], \"track\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249fd7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2438952883.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"points_earned_rank\"] = df.groupby(\"race_id\")[\"points_earned\"].rank(method=\"min\", ascending=False)\n"
     ]
    }
   ],
   "source": [
    "# create points_earned rank feature for points model\n",
    "df[\"points_earned_rank\"] = df.groupby(\"race_id\")[\"points_earned\"].rank(method=\"min\", ascending=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c354192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['starting_position', 'BestLapRank', 'OverAllAvgRank', 'finishing_position_lag1_general', 'finishing_position_roll3_general', 'finishing_position_roll5_general', 'finishing_position_roll10_general', 'starting_position_lag1_general', 'starting_position_roll3_general', 'starting_position_roll5_general', 'starting_position_roll10_general', 'points_position_lag1_general', 'points_position_roll3_general', 'points_position_roll5_general', 'points_position_roll10_general', 'stage_1_position_lag1_general', 'stage_1_position_roll3_general', 'stage_1_position_roll5_general', 'stage_1_position_roll10_general', 'stage_2_position_lag1_general', 'stage_2_position_roll3_general', 'stage_2_position_roll5_general', 'stage_2_position_roll10_general', 'mid_ps_lag1_general', 'mid_ps_roll3_general', 'mid_ps_roll5_general', 'mid_ps_roll10_general', 'closing_ps_lag1_general', 'closing_ps_roll3_general', 'closing_ps_roll5_general', 'closing_ps_roll10_general', 'avg_ps_lag1_general', 'avg_ps_roll3_general', 'avg_ps_roll5_general', 'avg_ps_roll10_general', 'BestLapRank_lag1_general', 'BestLapRank_roll3_general', 'BestLapRank_roll5_general', 'BestLapRank_roll10_general', 'OverAllAvgRank_lag1_general', 'OverAllAvgRank_roll3_general', 'OverAllAvgRank_roll5_general', 'OverAllAvgRank_roll10_general', 'laps_completed_lag1_general', 'laps_completed_roll3_general', 'laps_completed_roll5_general', 'laps_completed_roll10_general', 'laps_led_lag1_general', 'laps_led_roll3_general', 'laps_led_roll5_general', 'laps_led_roll10_general', 'points_earned_lag1_general', 'points_earned_roll3_general', 'points_earned_roll5_general', 'points_earned_roll10_general', 'fast_laps_lag1_general', 'fast_laps_roll3_general', 'fast_laps_roll5_general', 'fast_laps_roll10_general', 'top15_laps_lag1_general', 'top15_laps_roll3_general', 'top15_laps_roll5_general', 'top15_laps_roll10_general', 'rating_lag1_general', 'rating_roll3_general', 'rating_roll5_general', 'rating_roll10_general', 'finishing_position_lag1_tracktype', 'finishing_position_roll3_tracktype', 'finishing_position_roll5_tracktype', 'finishing_position_roll10_tracktype', 'starting_position_lag1_tracktype', 'starting_position_roll3_tracktype', 'starting_position_roll5_tracktype', 'starting_position_roll10_tracktype', 'points_position_lag1_tracktype', 'points_position_roll3_tracktype', 'points_position_roll5_tracktype', 'points_position_roll10_tracktype', 'stage_1_position_lag1_tracktype', 'stage_1_position_roll3_tracktype', 'stage_1_position_roll5_tracktype', 'stage_1_position_roll10_tracktype', 'stage_2_position_lag1_tracktype', 'stage_2_position_roll3_tracktype', 'stage_2_position_roll5_tracktype', 'stage_2_position_roll10_tracktype', 'mid_ps_lag1_tracktype', 'mid_ps_roll3_tracktype', 'mid_ps_roll5_tracktype', 'mid_ps_roll10_tracktype', 'closing_ps_lag1_tracktype', 'closing_ps_roll3_tracktype', 'closing_ps_roll5_tracktype', 'closing_ps_roll10_tracktype', 'avg_ps_lag1_tracktype', 'avg_ps_roll3_tracktype', 'avg_ps_roll5_tracktype', 'avg_ps_roll10_tracktype', 'BestLapRank_lag1_tracktype', 'BestLapRank_roll3_tracktype', 'BestLapRank_roll5_tracktype', 'BestLapRank_roll10_tracktype', 'OverAllAvgRank_lag1_tracktype', 'OverAllAvgRank_roll3_tracktype', 'OverAllAvgRank_roll5_tracktype', 'OverAllAvgRank_roll10_tracktype', 'laps_completed_lag1_tracktype', 'laps_completed_roll3_tracktype', 'laps_completed_roll5_tracktype', 'laps_completed_roll10_tracktype', 'laps_led_lag1_tracktype', 'laps_led_roll3_tracktype', 'laps_led_roll5_tracktype', 'laps_led_roll10_tracktype', 'points_earned_lag1_tracktype', 'points_earned_roll3_tracktype', 'points_earned_roll5_tracktype', 'points_earned_roll10_tracktype', 'fast_laps_lag1_tracktype', 'fast_laps_roll3_tracktype', 'fast_laps_roll5_tracktype', 'fast_laps_roll10_tracktype', 'top15_laps_lag1_tracktype', 'top15_laps_roll3_tracktype', 'top15_laps_roll5_tracktype', 'top15_laps_roll10_tracktype', 'rating_lag1_tracktype', 'rating_roll3_tracktype', 'rating_roll5_tracktype', 'rating_roll10_tracktype', 'finishing_position_lag1_track', 'finishing_position_roll3_track', 'finishing_position_roll5_track', 'starting_position_lag1_track', 'starting_position_roll3_track', 'starting_position_roll5_track', 'points_position_lag1_track', 'points_position_roll3_track', 'points_position_roll5_track', 'stage_1_position_lag1_track', 'stage_1_position_roll3_track', 'stage_1_position_roll5_track', 'stage_2_position_lag1_track', 'stage_2_position_roll3_track', 'stage_2_position_roll5_track', 'mid_ps_lag1_track', 'mid_ps_roll3_track', 'mid_ps_roll5_track', 'closing_ps_lag1_track', 'closing_ps_roll3_track', 'closing_ps_roll5_track', 'avg_ps_lag1_track', 'avg_ps_roll3_track', 'avg_ps_roll5_track', 'BestLapRank_lag1_track', 'BestLapRank_roll3_track', 'BestLapRank_roll5_track', 'OverAllAvgRank_lag1_track', 'OverAllAvgRank_roll3_track', 'OverAllAvgRank_roll5_track', 'laps_completed_lag1_track', 'laps_completed_roll3_track', 'laps_completed_roll5_track', 'laps_led_lag1_track', 'laps_led_roll3_track', 'laps_led_roll5_track', 'points_earned_lag1_track', 'points_earned_roll3_track', 'points_earned_roll5_track', 'fast_laps_lag1_track', 'fast_laps_roll3_track', 'fast_laps_roll5_track', 'top15_laps_lag1_track', 'top15_laps_roll3_track', 'top15_laps_roll5_track', 'rating_lag1_track', 'rating_roll3_track', 'rating_roll5_track']\n"
     ]
    }
   ],
   "source": [
    "# dropping features irrelevant to benchmark model\n",
    "\n",
    "# keeping for visibility when reviewing df as csv\n",
    "keep_cols = [\n",
    "    # target attribute here (finishing position or points for now)\n",
    "    \"finishing_position\", \n",
    "    # non-leaky identifiers\n",
    "    \"race_id\", \"race_season\", \"race_name\", \"track_name\", \"race_date\",\n",
    "    \"driver_fullname\", \"driver_id\", \"car_number\", \"team_name\", \"car_make\",\n",
    "    \"crew_chief_fullname\"\n",
    "]\n",
    "\n",
    "# remove the actual in-race data per observation but keep P&Q\n",
    "in_race_leakage = [\n",
    "    'finishing_position', 'laps_completed', 'laps_led', \n",
    "    'points_earned', 'playoff_points_earned', 'points_earned_rank',\n",
    "    'points_position', 'mid_ps', 'closing_ps', 'avg_ps', 'fast_laps', 'top15_laps', 'rating', \n",
    "    'stage_1_position', 'stage_2_position'\n",
    "]\n",
    "\n",
    "# keep engineered driver features for model, but not team / carteam features (those were only used to fill missing driver stats)\n",
    "lagroll_cols = [\n",
    "    col for col in df.columns\n",
    "    if any(feat in col for feat in lagroll_features)\n",
    "    and \"_team\" not in col\n",
    "    and \"_carteam\" not in col\n",
    "    and col not in in_race_leakage\n",
    "]\n",
    "print(lagroll_cols)\n",
    "\n",
    "# create a dataframe for finishing position model training\n",
    "finish_final_cols = keep_cols + lagroll_cols\n",
    "finishing_df = df[finish_final_cols]\n",
    "\n",
    "# edit for points earned model\n",
    "keep_cols.remove(\"finishing_position\")\n",
    "keep_cols.insert(0, \"points_earned_rank\")\n",
    "\n",
    "points_final_cols = keep_cols + lagroll_cols\n",
    "points_df = df[points_final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb9ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'ridge__alpha': 900}\n",
      "starting_position                  1.309176\n",
      "OverAllAvgRank                     0.509608\n",
      "mid_ps_roll10_general              0.467485\n",
      "BestLapRank                        0.427225\n",
      "OverAllAvgRank_roll5_general       0.410383\n",
      "points_position_roll10_general     0.371059\n",
      "OverAllAvgRank_roll3_tracktype     0.368401\n",
      "laps_led_roll5_tracktype           0.319602\n",
      "stage_1_position_roll10_general    0.319032\n",
      "BestLapRank_roll5_track            0.316061\n",
      "mid_ps_roll5_tracktype             0.286466\n",
      "OverAllAvgRank_roll5_track         0.277926\n",
      "laps_led_roll10_tracktype          0.269448\n",
      "points_earned_roll3_general        0.268917\n",
      "top15_laps_roll5_general           0.264521\n",
      "laps_led_roll10_general            0.255609\n",
      "avg_ps_roll5_track                 0.249727\n",
      "avg_ps_roll3_general               0.239579\n",
      "laps_completed_lag1_tracktype      0.213629\n",
      "laps_led_lag1_tracktype            0.211932\n",
      "dtype: float64\n",
      "\n",
      "Spearman mean: 0.446\n",
      "Spearman median: 0.48\n",
      "Number of races evaluated: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:60: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(race_spearman)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'ridge__alpha': 400}\n",
      "starting_position                     2.047002\n",
      "points_position_roll10_general        0.852749\n",
      "OverAllAvgRank_roll5_general          0.604803\n",
      "mid_ps_roll10_general                 0.562211\n",
      "points_position_lag1_general          0.545837\n",
      "avg_ps_roll3_general                  0.542289\n",
      "points_position_roll5_general         0.528179\n",
      "stage_1_position_roll10_general       0.492131\n",
      "OverAllAvgRank                        0.449712\n",
      "laps_led_roll5_tracktype              0.440865\n",
      "avg_ps_roll5_general                  0.419836\n",
      "avg_ps_roll10_general                 0.406798\n",
      "laps_led_roll10_general               0.402566\n",
      "BestLapRank                           0.397959\n",
      "top15_laps_roll5_general              0.390866\n",
      "starting_position_roll10_tracktype    0.344692\n",
      "rating_roll5_general                  0.331594\n",
      "rating_roll10_general                 0.329781\n",
      "OverAllAvgRank_roll3_tracktype        0.318511\n",
      "finishing_position_lag1_track         0.311261\n",
      "dtype: float64\n",
      "\n",
      "Spearman mean: 0.593\n",
      "Spearman median: 0.604\n",
      "Number of races evaluated: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_15936\\2718627296.py:60: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(race_spearman)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# Linear Regression Model Function\n",
    "\n",
    "def lr_model(training_df, lagroll_cols, target_col):\n",
    "    # Features and target\n",
    "    df_train = training_df.dropna(subset=[target_col]).copy()\n",
    "    X = df_train[lagroll_cols]\n",
    "    y = df_train[target_col]\n",
    "    groups = df_train[\"race_id\"]\n",
    "\n",
    "    # Define pipeline: impute -> scale -> model\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge())\n",
    "    ])\n",
    "\n",
    "    # Parameter grid for alpha\n",
    "    if target_col == \"finishing_position\":\n",
    "        param_grid = {\"ridge__alpha\": [800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200]}\n",
    "    elif target_col == \"points_earned_rank\":\n",
    "        param_grid = {\"ridge__alpha\": [100, 150, 200, 250, 300, 350, 400, 450, 500]}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid target column specified.\")\n",
    "\n",
    "    # Grouped CV\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "\n",
    "    # Grid search\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    grid.fit(X, y, groups=groups)\n",
    "\n",
    "    print(\"Best alpha:\", grid.best_params_)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Get coefficients\n",
    "    ridge_model = best_model.named_steps[\"ridge\"]\n",
    "    coef = pd.Series(ridge_model.coef_, index=lagroll_cols)\n",
    "    print(coef.sort_values(ascending=False).head(20))\n",
    "\n",
    "    # Apply to full df\n",
    "    training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
    "    training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)  \n",
    "\n",
    "    def race_spearman(g):\n",
    "        if g[\"weighted_score_lr\"].nunique() < 2:\n",
    "            return np.nan\n",
    "        return spearmanr(g[\"weighted_score_lr\"], g[target_col]).correlation\n",
    "\n",
    "    race_corrs = (\n",
    "        training_df.dropna(subset=[target_col])\n",
    "        .groupby(\"race_id\")\n",
    "        .apply(race_spearman)\n",
    "    )\n",
    "\n",
    "    print(\"\\nSpearman mean:\", race_corrs.mean().round(3))\n",
    "    print(\"Spearman median:\", race_corrs.median().round(3))\n",
    "    print(\"Number of races evaluated:\", race_corrs.notna().sum())\n",
    "\n",
    "    # remove lagroll columns before saving for comparison (cuts down csv file size significantly)\n",
    "    training_df = training_df.drop(columns=lagroll_cols)\n",
    "\n",
    "    if target_col == \"finishing_position\":\n",
    "        training_df.to_csv(\"lr_analysis_ready_finishing.csv\", index=False)\n",
    "    elif target_col == \"points_earned_rank\":\n",
    "        training_df.to_csv(\"lr_analysis_ready_points.csv\", index=False)\n",
    "    else: \n",
    "        raise ValueError(\"Invalid target column specified.\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# create the finishing position model\n",
    "lr_model(finishing_df, lagroll_cols, \"finishing_position\")\n",
    "\n",
    "# create the points earned model\n",
    "lr_model(points_df, lagroll_cols, \"points_earned_rank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
