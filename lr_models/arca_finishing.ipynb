{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc482fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# make parent folder importable\n",
    "parent_folder = Path.cwd().parent\n",
    "sys.path.append(str(parent_folder))\n",
    "\n",
    "# import config\n",
    "from config import DATA_DIR\n",
    "\n",
    "results_file = DATA_DIR / \"10-25-arca-results.csv\"\n",
    "practice_file = DATA_DIR / \"10-25-arca-practice.csv\"\n",
    "quali_file = DATA_DIR / \"10-25-arca-quali.csv\"\n",
    "\n",
    "results = pd.read_csv(results_file)\n",
    "practice = pd.read_csv(practice_file)\n",
    "qualifying = pd.read_csv(quali_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb6d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.copy()\n",
    "df = pd.merge(df, practice, on=[\"race_id\", \"driver_id\"], how=\"outer\", suffixes=(\"\", \"practice\"))\n",
    "df = pd.merge(df, qualifying, on=[\"race_id\", \"driver_id\"], how=\"outer\", suffixes=(\"\", \"qualifying\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2974c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [race_id, race_season, race_name, track_name, race_date, finishing_position, starting_position, car_number, driver_fullname, sponsor, car_make, laps_completed, laps_led, finishing_status, points_earned, driver_id, team_name, track_type, track_length, division, Pos, No., Name, Sponsor, Best Tm, Best Speed, In Lap, Laps, Diff, BestLapRank, Number, FullName, Sponsorqualifying, BestLapTime, BestLapSpeed, InLap, Lapsqualifying, Diffqualifying]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# shows duplicates (same driver_id AND race_id in multiple rows)\n",
    "dupes = df[df.duplicated(subset=[\"race_id\", \"driver_id\"], keep=False)]\n",
    "print(dupes.sort_values([\"race_id\", \"driver_id\"]))\n",
    "# ensure no duplicates\n",
    "assert df.duplicated(subset=[\"race_id\", \"driver_id\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c713ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, rolling_lagging as rolling_lagging\n",
    "importlib.reload(rolling_lagging)\n",
    "from rolling_lagging import lagging_rolling_generator, reconcile_driver_carteams\n",
    "\n",
    "lagroll_features = [\n",
    "    \"finishing_position\", \n",
    "    \"starting_position\",\n",
    "    \"laps_completed\", \n",
    "    \"laps_led\", \n",
    "    \"points_earned\",\n",
    "    \"BestLapTime\",\n",
    "    \"BestLapSpeed\",\n",
    "    \"Diffqualifying\",\n",
    "    \"Best Tm\",\n",
    "    \"Best Speed\",\n",
    "    \"Diff\"\n",
    "]\n",
    "\n",
    "# feature engineering, lagging & rolling averages\n",
    "# df, features, sort_list, filter_list, windows_list, suffix, min_periods = 1\n",
    "\n",
    "# directly recent races (momentum):\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\"], [3, 5, 10], \"general\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\"], [3, 5, 10], \"general_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\"], [3, 5, 10], \"general_carteam\", 1)\n",
    "\n",
    "# most recent at track type:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_type\"], [3, 5], \"tracktype\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_type\"], [3, 5], \"tracktype_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_type\"], [3, 5], \"tracktype_carteam\", 1)\n",
    "\n",
    "# most recent at specific track:\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"driver_id\"], [\"driver_id\", \"track_name\"], [3], \"track\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\"], [\"team_name\", \"track_name\"], [3], \"track_team\", 1)\n",
    "df = lagging_rolling_generator(df, lagroll_features, [\"team_name\", \"car_number\"], [\"team_name\", \"car_number\", \"track_name\"], [3], \"track_carteam\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a6f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaNs in lagroll features with carteam or team averages\n",
    "# df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5, 10], \"general\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3, 5], \"tracktype\")\n",
    "df = reconcile_driver_carteams(df, lagroll_features, [3], \"track\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bd938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['starting_position', 'Best Tm', 'Best Speed', 'Diff', 'BestLapTime', 'BestLapSpeed', 'Diffqualifying', 'finishing_position_lag1_general', 'finishing_position_roll3_general', 'finishing_position_roll5_general', 'finishing_position_roll10_general', 'starting_position_lag1_general', 'starting_position_roll3_general', 'starting_position_roll5_general', 'starting_position_roll10_general', 'laps_completed_lag1_general', 'laps_completed_roll3_general', 'laps_completed_roll5_general', 'laps_completed_roll10_general', 'laps_led_lag1_general', 'laps_led_roll3_general', 'laps_led_roll5_general', 'laps_led_roll10_general', 'points_earned_lag1_general', 'points_earned_roll3_general', 'points_earned_roll5_general', 'points_earned_roll10_general', 'BestLapTime_lag1_general', 'BestLapTime_roll3_general', 'BestLapTime_roll5_general', 'BestLapTime_roll10_general', 'BestLapSpeed_lag1_general', 'BestLapSpeed_roll3_general', 'BestLapSpeed_roll5_general', 'BestLapSpeed_roll10_general', 'Diffqualifying_lag1_general', 'Diffqualifying_roll3_general', 'Diffqualifying_roll5_general', 'Diffqualifying_roll10_general', 'Best Tm_lag1_general', 'Best Tm_roll3_general', 'Best Tm_roll5_general', 'Best Tm_roll10_general', 'Best Speed_lag1_general', 'Best Speed_roll3_general', 'Best Speed_roll5_general', 'Best Speed_roll10_general', 'Diff_lag1_general', 'Diff_roll3_general', 'Diff_roll5_general', 'Diff_roll10_general', 'finishing_position_lag1_tracktype', 'finishing_position_roll3_tracktype', 'finishing_position_roll5_tracktype', 'starting_position_lag1_tracktype', 'starting_position_roll3_tracktype', 'starting_position_roll5_tracktype', 'laps_completed_lag1_tracktype', 'laps_completed_roll3_tracktype', 'laps_completed_roll5_tracktype', 'laps_led_lag1_tracktype', 'laps_led_roll3_tracktype', 'laps_led_roll5_tracktype', 'points_earned_lag1_tracktype', 'points_earned_roll3_tracktype', 'points_earned_roll5_tracktype', 'BestLapTime_lag1_tracktype', 'BestLapTime_roll3_tracktype', 'BestLapTime_roll5_tracktype', 'BestLapSpeed_lag1_tracktype', 'BestLapSpeed_roll3_tracktype', 'BestLapSpeed_roll5_tracktype', 'Diffqualifying_lag1_tracktype', 'Diffqualifying_roll3_tracktype', 'Diffqualifying_roll5_tracktype', 'Best Tm_lag1_tracktype', 'Best Tm_roll3_tracktype', 'Best Tm_roll5_tracktype', 'Best Speed_lag1_tracktype', 'Best Speed_roll3_tracktype', 'Best Speed_roll5_tracktype', 'Diff_lag1_tracktype', 'Diff_roll3_tracktype', 'Diff_roll5_tracktype', 'finishing_position_lag1_track', 'finishing_position_roll3_track', 'starting_position_lag1_track', 'starting_position_roll3_track', 'laps_completed_lag1_track', 'laps_completed_roll3_track', 'laps_led_lag1_track', 'laps_led_roll3_track', 'points_earned_lag1_track', 'points_earned_roll3_track', 'BestLapTime_lag1_track', 'BestLapTime_roll3_track', 'BestLapSpeed_lag1_track', 'BestLapSpeed_roll3_track', 'Diffqualifying_lag1_track', 'Diffqualifying_roll3_track', 'Best Tm_lag1_track', 'Best Tm_roll3_track', 'Best Speed_lag1_track', 'Best Speed_roll3_track', 'Diff_lag1_track', 'Diff_roll3_track']\n"
     ]
    }
   ],
   "source": [
    "# dropping features irrelevant to benchmark model\n",
    "\n",
    "# keeping for visibility when reviewing df as csv\n",
    "keep_cols = [\n",
    "    # target attribute here (finishing position or points for now)\n",
    "    \"finishing_position\", \n",
    "    # non-leaky identifiers\n",
    "    \"race_id\", \"race_season\", \"race_name\", \"track_name\", \"race_date\",\n",
    "    \"driver_fullname\", \"driver_id\", \"car_number\", \"team_name\", \"car_make\"\n",
    "]\n",
    "\n",
    "# remove the actual in-race data per observation but keep P&Q\n",
    "in_race_leakage = [\n",
    "    'finishing_position', 'laps_completed', 'laps_led', 'points_earned'\n",
    "]\n",
    "\n",
    "# keep engineered driver features for model, but not team / carteam features (those were only used to fill missing driver stats)\n",
    "lagroll_cols = [\n",
    "    col for col in df.columns\n",
    "    if any(feat in col for feat in lagroll_features)\n",
    "    and \"_team\" not in col\n",
    "    and \"_carteam\" not in col\n",
    "    and col not in in_race_leakage\n",
    "]\n",
    "print(lagroll_cols)\n",
    "\n",
    "# create a dataframe for finishing position model training\n",
    "finish_final_cols = keep_cols + lagroll_cols\n",
    "finishing_df = df[finish_final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327f190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'ridge__alpha': 90}\n",
      "starting_position                    4.430637\n",
      "finishing_position_lag1_track        0.978595\n",
      "laps_completed_roll3_track           0.637706\n",
      "BestLapSpeed                         0.605975\n",
      "BestLapTime                          0.593498\n",
      "BestLapSpeed_lag1_general            0.586826\n",
      "starting_position_roll5_tracktype    0.519929\n",
      "Best Speed                           0.437428\n",
      "starting_position_roll3_tracktype    0.430352\n",
      "Diff                                 0.402776\n",
      "laps_completed_lag1_tracktype        0.399187\n",
      "starting_position_roll5_general      0.392216\n",
      "finishing_position_roll3_track       0.382833\n",
      "Diffqualifying_roll3_tracktype       0.380491\n",
      "Diffqualifying_roll5_tracktype       0.369762\n",
      "laps_led_roll3_tracktype             0.324416\n",
      "Diff_roll5_general                   0.316379\n",
      "laps_led_lag1_track                  0.313517\n",
      "Best Speed_lag1_tracktype            0.301827\n",
      "laps_led_roll5_general               0.277302\n",
      "dtype: float64\n",
      "\n",
      "Spearman mean: 0.693\n",
      "Spearman median: 0.699\n",
      "Number of races evaluated: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_11520\\2494746756.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_11520\\2494746756.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_11520\\2494746756.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_11520\\2494746756.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)\n",
      "C:\\Users\\joeah\\AppData\\Local\\Temp\\ipykernel_11520\\2494746756.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(race_spearman)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# Linear Regression Model Function\n",
    "\n",
    "def lr_model(training_df, lagroll_cols, target_col):\n",
    "    # Features and target\n",
    "    df_train = training_df.dropna(subset=[target_col]).copy()\n",
    "    X = df_train[lagroll_cols]\n",
    "    y = df_train[target_col]\n",
    "    groups = df_train[\"race_id\"]\n",
    "\n",
    "    # Define pipeline: impute -> scale -> model\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge())\n",
    "    ])\n",
    "\n",
    "    # Parameter grid for alpha\n",
    "    if target_col == \"finishing_position\":\n",
    "        param_grid = {\"ridge__alpha\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid target column specified.\")\n",
    "\n",
    "    # Grouped CV\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "\n",
    "    # Grid search\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    grid.fit(X, y, groups=groups)\n",
    "\n",
    "    print(\"Best alpha:\", grid.best_params_)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Get coefficients\n",
    "    ridge_model = best_model.named_steps[\"ridge\"]\n",
    "    coef = pd.Series(ridge_model.coef_, index=lagroll_cols)\n",
    "    print(coef.sort_values(ascending=False).head(20))\n",
    "\n",
    "    # Apply to full df\n",
    "    training_df[\"weighted_score_lr\"] = best_model.predict(training_df[lagroll_cols])\n",
    "    training_df[\"pred_rank_lr\"] = training_df.groupby(\"race_id\")[\"weighted_score_lr\"].rank(method=\"min\", ascending=True)  \n",
    "\n",
    "    def race_spearman(g):\n",
    "        if g[\"weighted_score_lr\"].nunique() < 2:\n",
    "            return np.nan\n",
    "        return spearmanr(g[\"weighted_score_lr\"], g[target_col]).correlation\n",
    "\n",
    "    race_corrs = (\n",
    "        training_df.dropna(subset=[target_col])\n",
    "        .groupby(\"race_id\")\n",
    "        .apply(race_spearman)\n",
    "    )\n",
    "\n",
    "    print(\"\\nSpearman mean:\", race_corrs.mean().round(3))\n",
    "    print(\"Spearman median:\", race_corrs.median().round(3))\n",
    "    print(\"Number of races evaluated:\", race_corrs.notna().sum())\n",
    "\n",
    "    # remove lagroll columns before saving for comparison (cuts down csv file size significantly)\n",
    "    training_df = training_df.drop(columns=lagroll_cols)\n",
    "\n",
    "    if target_col == \"finishing_position\":\n",
    "        training_df.to_csv(\"arca_lr_analysis_ready_finishing.csv\", index=False)\n",
    "    else: \n",
    "        raise ValueError(\"Invalid target column specified.\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# create the finishing position model\n",
    "lr_model(finishing_df, lagroll_cols, \"finishing_position\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
